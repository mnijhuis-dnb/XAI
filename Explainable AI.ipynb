{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mnijhuis-dnb/XAI/blob/main/Explainable%20AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzjAFEvQO7yo"
      },
      "source": [
        "## Explainable AI \n",
        "\n",
        "*\tPermutation importance with ELI5\n",
        "*\tPartial dependency plots\n",
        "*\tShapley values\n",
        "\n",
        "<br/>\n",
        "\n",
        "6 June 2023  \n",
        "\n",
        "**Instructors**  \n",
        "Michiel Nijhuis (m.nijhuis@dnb.nl)  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "au5kt-MWxS9c"
      },
      "source": [
        "### Data loading\n",
        "\n",
        "For this tutorial we will use the US census income dataset: \n",
        "https://archive.ics.uci.edu/ml/datasets/Census-Income+%28KDD%29\n",
        "\n",
        "We will start with the installation of the packages we are going to use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_9Zj8yZTDMyP",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "!pip install shap\n",
        "!pip install eli5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B_3omjbAJ303",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIujChx5G142"
      },
      "source": [
        "Downloading and installing the data which will be used"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJbgZuqfHDXt",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "!gdown 131MoEFF9OEY9x61yMi_2fZmzJnt4P4qu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDNbsKK3enTq"
      },
      "source": [
        "Reading in the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jxbVTcnnI2bP",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "dtypes = [\n",
        "\t('age', 'float32'), ('class of worker', 'category'), ('detailed industry recode', 'category'), \n",
        "\t('detailed occupation recode', 'category'), ('education', 'category'), ('wage per hour', 'float32'), \n",
        "\t('enroll in edu inst last wk', 'category'), ('marital stat', 'category'), ('major industry code', 'category'), \n",
        "\t('major occupation code', 'category'), ('race', 'category'), ('hispanic origin', 'category'), \n",
        "\t('sex', 'category'), ('member of a labor union', 'category'), ('reason for unemployment', 'category'), \n",
        "\t('full or part time employment stat', 'category'), ('capital gains', 'float32'), \n",
        "\t('capital losses', 'float32'), ('dividends from stocks', 'float32'), ('tax filer stat', 'category'), \n",
        "\t('region of previous residence', 'category'), ('state of previous residence', 'category'), \n",
        "\t('detailed household and family stat', 'category'), ('detailed household summary in household', 'category'), \n",
        "\t('instance weight_ignore', 'float32'), ('migration code-change in msa', 'category'), \n",
        "\t('migration code-change in reg', 'category'), ('migration code-move within reg', 'category'), \n",
        "\t('live in this house 1 year ago', 'category'), ('migration prev res in sunbelt', 'category'), \n",
        "\t('num persons worked for employer', 'float32'),\t('family members under 18', 'category'), \n",
        "\t('country of birth father', 'category'), ('country of birth mother', 'category'), \n",
        "\t('country of birth self', 'category'), ('citizenship', 'category'), ('own business or self employed', 'category'), \n",
        "\t('fill inc questionnaire for veteran\\'s admin', 'category'), ('veterans benefits', 'category'), \n",
        "\t('weeks worked in year', 'float32'), ('year', 'category'), ('targets', 'category')]\n",
        "\n",
        "raw_data = pd.read_csv('/content/census-income.data', names=[d[0] for d in dtypes], dtype=dict(dtypes))\n",
        "\n",
        "edu_code = {\"Children\": 0,\n",
        "            \"Less than 1st grade\": 1,  \n",
        "            \"1st 2nd 3rd or 4th grade\": 2,  \n",
        "            \"5th or 6th grade\": 3, \n",
        "            \"7th and 8th grade\": 4, \n",
        "            \"9th grade\": 5, \n",
        "            \"10th grade\": 6, \n",
        "            \"11th grade\": 7, \n",
        "            \"12th grade no diploma\": 8, \n",
        "            \"High school graduate\": 9,\n",
        "            \"Some college but no degree\": 10,\n",
        "            \"Associates degree-academic program\": 11, \n",
        "            \"Associates degree-occup /vocational\": 12,\n",
        "            \"Bachelors degree(BA AB BS)\": 13,\n",
        "            \"Masters degree(MA MS MEng MEd MSW MBA)\": 14,  \n",
        "            \"Prof school degree (MD DDS DVM LLB JD)\": 15,\n",
        "            \"Doctorate degree(PhD EdD)\": 15}\n",
        "raw_data['education-num'] = np.array([edu_code[v.strip()] for v in raw_data['education']]).astype('float32')\n",
        "dtypes.append(('education-num','float32'))\n",
        "\n",
        "targets, target_value = pd.factorize(raw_data['targets'])\n",
        "raw_data = raw_data.drop(columns=['instance weight_ignore', 'targets'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmecZtx6J9PK"
      },
      "source": [
        "Some data cleanup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FaJpQwC6Dm-O",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# remove some of the data to make it calculate quicker\n",
        "data = raw_data.drop(columns=['detailed industry recode', 'detailed occupation recode', \n",
        "                              'major industry code', 'major occupation code', 'education', \n",
        "                              'country of birth father',  'country of birth mother', \n",
        "                              'country of birth self', 'state of previous residence', \n",
        "                              'detailed household and family stat'])\n",
        "data_for_plot = data.copy()\n",
        "binary_columns = ['sex','member of a labor union','live in this house 1 year ago',\n",
        "                   'migration prev res in sunbelt','own business or self employed',\n",
        "                   'fill inc questionnaire for veteran\\'s admin','veterans benefits',\n",
        "                   'year']\n",
        "\n",
        "binary_data = data[binary_columns].copy()\n",
        "categorical_data = data.select_dtypes(include=['category']).drop(columns=binary_data)\n",
        "numerical_data = data.select_dtypes(include=['float32'])\n",
        "\n",
        "binary_data[(binary_data==' 2') | (binary_data==' ?') | (binary_data==' Not in universe') | (binary_data==' Not in universe under 1 year old')] = np.nan\n",
        "\n",
        "binary_data = (binary_data.apply(lambda x: pd.factorize(x)[0]))\n",
        "\n",
        "categorical_data = categorical_data.apply(lambda x : pd.factorize(x)[0])\n",
        "data = pd.DataFrame(np.hstack((categorical_data,numerical_data.values, binary_data.values)),\n",
        "                     columns=list(categorical_data.columns) + list(numerical_data.columns) + list(binary_data.columns))\n",
        "data = data.reindex(columns=data_for_plot.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35f82C5cPRPK"
      },
      "source": [
        "Making a test-train split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NtUuyYeYPTs9",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "train_x, val_x, train_y, val_y = train_test_split(data, pd.Series(targets), random_state=99)\n",
        "\n",
        "index = np.random.permutation(np.hstack((train_y.index.values[train_y==1],np.random.permutation(train_y.index.values[train_y==0])))[:2*np.sum(train_y==1)])\n",
        "train_x_new = train_x.loc[index]\n",
        "train_y_new = train_y.loc[index]\n",
        "\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrE035fHJ_l1"
      },
      "source": [
        "Building a model..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AAzAtAR_Dfbd",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "my_model = RandomForestClassifier(random_state=99, min_samples_split=500, max_leaf_nodes=50, oob_score=True).fit(train_x_new, train_y_new)\n",
        "print(f'Model accuracy: {np.round(np.sum(my_model.predict(val_x)==val_y)/len(val_y)*100,1)}%')\n",
        "print(f'Model recall: {np.round(np.sum((my_model.predict(val_x)==1) & (val_y==1))/np.sum(val_y==1)*100,1)}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TR4MSs3CxV4E"
      },
      "source": [
        "### ELI5\n",
        "Calculating feature importance with eli5:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GPAlf0r7xWVk",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import eli5\n",
        "from eli5.sklearn import PermutationImportance\n",
        "\n",
        "perm = PermutationImportance(my_model, random_state=1, scoring='recall').fit(train_x_new, train_y_new)\n",
        "eli5.show_weights(perm, feature_names = data.columns.to_list(), top=50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7M5ZwFqBWp2"
      },
      "source": [
        "### Partial dependence plots\n",
        "Now we will create a couple of partial dependence plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gy9McMxbBazn",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.inspection import PartialDependenceDisplay\n",
        "\n",
        "pdp_age = PartialDependenceDisplay.from_estimator(my_model, val_x, ['age'], grid_resolution=20)\n",
        "plt.setp(pdp_age.deciles_vlines_, visible=False);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sbx1QdI_BX_O",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "pdp_education = PartialDependenceDisplay.from_estimator(my_model, val_x, ['education-num'], kind='both',  grid_resolution=20)\n",
        "plt.setp(pdp_education.deciles_vlines_, visible=False);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dd5_qB0NBhUO"
      },
      "source": [
        "Also works with contour plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e-B9IVlzBi0m",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "features_to_plot = ('age', 'education-num')\n",
        "\n",
        "pdp_2d = PartialDependenceDisplay.from_estimator(my_model, val_x, [features_to_plot], grid_resolution=20)\n",
        "plt.setp(pdp_2d.deciles_vlines_, visible=False);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9SCLca3B-l3"
      },
      "source": [
        "### SHAP\n",
        "Now we will take a look at the Shapley values for a single row"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shap"
      ],
      "metadata": {
        "id": "XvcnXrmAy2SS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T9PgEWwcCBGu",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "row_number = 79\n",
        "data_for_prediction = val_x.iloc[row_number]  \n",
        "my_model.predict_proba(data_for_prediction.values.reshape(1, -1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iM2fVJCFCEtV",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "explainer = shap.TreeExplainer(my_model)\n",
        "shap_values = explainer.shap_values(data_for_prediction)\n",
        "shap_values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OnicgnOCHcd"
      },
      "source": [
        "SHAP also has nice visualizations for these values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "41kQ46DKCIzl",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "shap.initjs()\n",
        "shap.waterfall_plot(shap.Explanation(values=shap_values[1], \n",
        "                                     base_values=explainer.expected_value[1], \n",
        "                                     data=val_x.iloc[row_number],  \n",
        "                                     feature_names=data_for_plot.loc[val_x.index[row_number]].index.tolist()))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shap.initjs()\n",
        "shap.force_plot(explainer.expected_value[1], shap_values[1], data_for_plot.loc[val_x.index[row_number]])"
      ],
      "metadata": {
        "id": "I3N3xdsyDmtk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyh9QuaZCKWf"
      },
      "source": [
        "For non tree based models we can use the KernelExplainer to get an approximate result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VxM8eQATCMQt",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "shap.initjs()\n",
        "k_explainer = shap.KernelExplainer(my_model.predict, shap.kmeans(val_x, 54))\n",
        "k_shap_values = k_explainer.shap_values(data_for_prediction)\n",
        "shap.force_plot(k_explainer.expected_value, k_shap_values, data_for_plot.loc[val_x.index[row_number]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EN-0xnTOW3Rf"
      },
      "source": [
        "Calculating the Shapley values of 10000 random rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZoVFNvTW3mC",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "explainer = shap.TreeExplainer(my_model)\n",
        "random_subset = val_x.sample(n=10000)\n",
        "shap_values = explainer.shap_values(random_subset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVcG3_qqCQN9"
      },
      "source": [
        "Now we can plot the results for multiple the rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oNPueQ12IOrv",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "shap.initjs()\n",
        "shap.force_plot(explainer.expected_value[1], shap_values[1][:1000], data_for_plot.loc[random_subset.index[:1000]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJRFJbPnCWRM"
      },
      "source": [
        "We can get a summary of the Shapley values as follows\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ZhJeDbUCWl9",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "shap_values = explainer.shap_values(random_subset)\n",
        "shap.summary_plot(shap_values[1], random_subset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xo3KDrDKJVIW"
      },
      "source": [
        "Or for the combined features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4px0MPBBfUED",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "shap.summary_plot(shap_values[0], random_subset, plot_type='bar')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DT2-uHDJacF"
      },
      "source": [
        "Or for the dependence between 2 features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bWk_334Cfo7D",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "shap.dependence_plot('age', shap_values[1], random_subset, interaction_index='sex', x_jitter=1, dot_size=10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns"
      ],
      "metadata": {
        "id": "UwhuXjuNmoFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap.dependence_plot('weeks worked in year', shap_values[1], random_subset, interaction_index='capital losses', x_jitter=1, dot_size=20)"
      ],
      "metadata": {
        "id": "uIZ2mZJVl-7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check for fairness"
      ],
      "metadata": {
        "id": "-_A5NOszqft_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Times more likely that a male makes more than 50k = {targets[data['sex']==1].mean()/targets[data['sex']==0].mean()}\")"
      ],
      "metadata": {
        "id": "Ja51EWjVzh0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Times more likely that a male makes more than 50k = {my_model.predict(data[data['sex']==1]).mean()/my_model.predict(data[data['sex']==0]).mean()}\")"
      ],
      "metadata": {
        "id": "wEkuNNrGtXMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('original accuracy and recall')\n",
        "print(f'Model accuracy: {np.round(np.sum(my_model.predict(val_x)==val_y)/len(val_y)*100,1)}%')\n",
        "print(f'Model recall: {np.round(np.sum((my_model.predict(val_x)==1) & (val_y==1))/np.sum(val_y==1)*100,1)}%')"
      ],
      "metadata": {
        "id": "EdZHfw9T11DM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_names = data_for_plot.loc[val_x.index].columns.to_list()\n",
        "\n",
        "new_data = data.copy()\n",
        "new_data['sex'] = 0\n",
        "train_x, val_x, train_y, val_y = train_test_split(new_data, pd.Series(targets), random_state=99)\n",
        "\n",
        "index = np.random.permutation(np.hstack((train_y.index.values[train_y==1],np.random.permutation(train_y.index.values[train_y==0])))[:2*np.sum(train_y==1)])\n",
        "train_x_new = train_x.loc[index]\n",
        "train_y_new = train_y.loc[index]\n",
        "\n",
        "my_model = RandomForestClassifier(random_state=99, min_samples_split=500, max_leaf_nodes=50, oob_score=True).fit(train_x_new, train_y_new)\n",
        "\n",
        "explainer = shap.TreeExplainer(my_model)\n",
        "random_subset = val_x.sample(n=10000)\n",
        "shap_values = explainer.shap_values(random_subset)\n",
        "\n",
        "print(f'Model accuracy: {np.round(np.sum(my_model.predict(val_x)==val_y)/len(val_y)*100,1)}%')\n",
        "print(f'Model recall: {np.round(np.sum((my_model.predict(val_x)==1) & (val_y==1))/np.sum(val_y==1)*100,1)}%')"
      ],
      "metadata": {
        "id": "RGvrYoRxqvrs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Times more likely that a male makes more than 50k = {my_model.predict(data[data['sex']==1]).mean()/my_model.predict(data[data['sex']==0]).mean()}\")"
      ],
      "metadata": {
        "id": "F7x98iCDvsaJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap.group_difference_plot(shap_values[1], data_for_plot.loc[random_subset.index, 'sex']==' Female', feature_names)"
      ],
      "metadata": {
        "id": "ixRfPlbxmeus"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_names = data_for_plot.loc[val_x.index].columns.to_list()\n",
        "\n",
        "new_data['detailed household summary in household'] = 0\n",
        "train_x, val_x, train_y, val_y = train_test_split(new_data, pd.Series(targets), random_state=99)\n",
        "\n",
        "index = np.random.permutation(np.hstack((train_y.index.values[train_y==1],np.random.permutation(train_y.index.values[train_y==0])))[:2*np.sum(train_y==1)])\n",
        "train_x_new = train_x.loc[index]\n",
        "train_y_new = train_y.loc[index]\n",
        "\n",
        "my_model = RandomForestClassifier(random_state=99, min_samples_split=500, max_leaf_nodes=50, oob_score=True).fit(train_x_new, train_y_new)\n",
        "\n",
        "explainer = shap.TreeExplainer(my_model)\n",
        "random_subset = val_x.sample(n=10000)\n",
        "shap_values = explainer.shap_values(random_subset)\n",
        "\n",
        "print(f'Model accuracy: {np.round(np.sum(my_model.predict(val_x)==val_y)/len(val_y)*100,1)}%')\n",
        "print(f'Model recall: {np.round(np.sum((my_model.predict(val_x)==1) & (val_y==1))/np.sum(val_y==1)*100,1)}%')"
      ],
      "metadata": {
        "id": "wb22jOwwqPX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Times more likely that a male makes more than 50k = {my_model.predict(data[data['sex']==1]).mean()/my_model.predict(data[data['sex']==0]).mean()}\")"
      ],
      "metadata": {
        "id": "0_QE6XnEvupK"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Explainable ML.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}